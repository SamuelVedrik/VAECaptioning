{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Introduction\n",
    "#### Variational Autoencoder for Deep Learning of Images, Labels and Captions\n",
    "\n",
    "This notebook aims to document the process of implementing [this paper](https://proceedings.neurips.cc/paper/2016/file/eb86d510361fc23b59f18c1bc9802cc6-Paper.pdf) from scratch.\n",
    "I used [this article](https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73) to help me get a better intution of what varitional autoencoders do. I recently learnt about autoencoders from my dimensionality reduction class in CSC311 offered by UofT, however they just gave us a very brief introduction to them. Nevertheless, the intutions of the varitional autoencoder makes sense to me. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "#### Convolution Review\n",
    "\n",
    "I was quite rusty with how traditional convolutions networks worked, and so I had to do a quick review. [This article](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53) was a great help for getting me to re-understand it much quicker. \n",
    "\n",
    "Diving deep into \"convolution\" and \"cross correlation\" lead into a lot of signal processing which I am unfamiliar with. I feel that all I need to know is that convolution performs cross correlation with flipped kernels. Pytorch performs cross correlation, so I won't have to flip kernels here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import itertools\n",
    "import torch.nn.init as init\n",
    "import math\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "a_test = np.array([[[1, 2, 0, 0],\n",
    "               [5, 3, 0, 4],\n",
    "               [0, 0, 0, 7],\n",
    "               [9, 3, 0, 0]], \n",
    "              \n",
    "              [[7, 2, 2, 0],\n",
    "               [4, 3, 0, 1],\n",
    "               [0, 5, 0, 0],\n",
    "               [0, 2, 1, 1]]])\n",
    "\n",
    "k_test = np.array([[[1,1,1],[1,1,0],[1,0,0]], [[1,1,1],[1,0,1],[1,1,1]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10, 24, 11,  3],\n",
       "       [25, 31, 18,  6],\n",
       "       [22, 27, 23, 14],\n",
       "       [16, 18, 18,  8]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndimage.correlate(a_test[0, ...], k_test[0, ...], mode='constant', cval=0) + \\\n",
    "ndimage.correlate(a_test[1, ...], k_test[1, ...], mode='constant', cval=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "tensor_a = torch.FloatTensor(a_test[np.newaxis, ...])\n",
    "tensor_k = torch.FloatTensor(k_test[np.newaxis, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[10., 24., 11.,  3.],\n",
       "          [25., 31., 18.,  6.],\n",
       "          [22., 27., 23., 14.],\n",
       "          [16., 18., 18.,  8.]]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.conv2d(tensor_a, tensor_k, padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_test = torch.rand(1, 1, 5, 5)\n",
    "k_test = torch.rand(2, 1, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[1.4389689 , 1.4598359 , 1.1263909 , 1.8594548 , 0.6488163 ],\n",
       "         [0.78488284, 2.7419467 , 1.8997619 , 2.7416952 , 1.9434671 ],\n",
       "         [0.60240835, 1.913981  , 2.518033  , 3.3335333 , 1.7734939 ],\n",
       "         [1.0321358 , 2.7392247 , 2.1393223 , 3.493859  , 2.0823443 ],\n",
       "         [1.1436785 , 1.2760688 , 1.6037238 , 1.5633086 , 1.0266767 ]],\n",
       "\n",
       "        [[0.6541255 , 1.5859987 , 1.1002768 , 1.4345604 , 0.64612865],\n",
       "         [1.2498124 , 2.3528025 , 1.5224932 , 3.0219288 , 1.2639134 ],\n",
       "         [0.6535807 , 2.1864336 , 2.107514  , 3.0801897 , 1.740164  ],\n",
       "         [1.0703773 , 2.4792154 , 2.5106044 , 3.3405318 , 1.805935  ],\n",
       "         [0.5606632 , 1.8344826 , 1.4250896 , 1.8167228 , 1.177574  ]]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack([ndimage.correlate(a_test[0, ...], k_test[0, ...], mode='constant', cval=0), \\\n",
    "         ndimage.correlate(a_test[0, ...], k_test[1, ...], mode='constant', cval=0)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.4390, 1.4598, 1.1264, 1.8595, 0.6488],\n",
       "          [0.7849, 2.7419, 1.8998, 2.7417, 1.9435],\n",
       "          [0.6024, 1.9140, 2.5180, 3.3335, 1.7735],\n",
       "          [1.0321, 2.7392, 2.1393, 3.4939, 2.0823],\n",
       "          [1.1437, 1.2761, 1.6037, 1.5633, 1.0267]],\n",
       "\n",
       "         [[0.6541, 1.5860, 1.1003, 1.4346, 0.6461],\n",
       "          [1.2498, 2.3528, 1.5225, 3.0219, 1.2639],\n",
       "          [0.6536, 2.1864, 2.1075, 3.0802, 1.7402],\n",
       "          [1.0704, 2.4792, 2.5106, 3.3405, 1.8059],\n",
       "          [0.5607, 1.8345, 1.4251, 1.8167, 1.1776]]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.conv2d(a_test, k_test, padding=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Image decoder: DDGM\n",
    "\n",
    "First I have to create the operation defined in (1) and (3).  \n",
    "\n",
    "For the convolution, it wasn't clear to me what the padding and stride were, so I assumed that we stick to CNN conventions and make the output shape the same as the input shape. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "def DDGM_convolve(D, S):\n",
    "    \"\"\"\n",
    "    Perform sum_(kl) D^(kl, l) * S^(n, kl, l) as described in the paper. \n",
    "    D: 4D tensor with shape (KL-1, KL, kW, kH)\n",
    "        KL-1: Number of \"slices\" in the previous layer. I.e the out channel. \n",
    "        KL: Number of \"slices\" in the current layer. I.e the in channel.\n",
    "        kW, kH: kernel width and kernel height\n",
    "    \n",
    "    S: 3D tensor with the shape (KL, cW, cH)\n",
    "        KL: Number of 2D slices\n",
    "        iW, iH: code width and code height\n",
    "    \"\"\"\n",
    "    result = None\n",
    "    kernel_size = D.shape[2]\n",
    "    for i in range(D.shape[1]):\n",
    "        D_kl = D[:, i, ...].unsqueeze(1)\n",
    "        S_kl = S[i, ...].unsqueeze(0).unsqueeze(0)\n",
    "        current_sum = F.conv2d(S_kl, D_kl, stride=1, padding=(kernel_size-1)//2)\n",
    "        \n",
    "        if result is None:\n",
    "            result = current_sum\n",
    "        else:\n",
    "            result += current_sum\n",
    "        \n",
    "    return result.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 28, 28])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = torch.rand((5, 3, 5, 5), requires_grad=True)\n",
    "S = torch.rand((3, 28, 28))\n",
    "DDGM_convolve(D, S).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Then, I have to create a unpooling layer as defined in (2). I copied an excerpt of it here: \n",
    "\n",
    "\n",
    "For the stochastic unpooling, $S^{(n,k1 ,1)}$ is partitioned into contiguous $px × py$ pooling blocks (analogous to pooling blocks in CNN-based activation maps). Let $ z^{(n,k1 ,1)}_{i, j} \\in \\{0, 1\\}^{px py}$ be a vector\n",
    "of $pxpy − 1$ zeros, and a single one; $z^{(n,k1 ,1)}_{i, j}$ corresponds to pooling block $(i, j)$ in $S^{(n,k1 ,1)}$. \n",
    "\n",
    "\n",
    "The location of the non-zero element of $z^{(n,k1 ,1)}_{i, j} $ identifies the location of the single non-zero element $i,j$\n",
    "in the corresponding pooling block of $S^{(n,k1 ,1)}$. \n",
    "\n",
    "\n",
    "The non-zero element in pooling block $(i,j)$ of $S^{(n,k1 ,1)}$ is set to $\\tilde{S}_{i, j}^{(n,k1,2)}$, i.e., element $(i,j)$ in slice k1 of $\\tilde{S}^{(n,2)}$. \n",
    "\n",
    "Within the prior of the decoder, we impose z(n,k1,1) ∼ Mult(1; 1/(pxpy), . . . , 1/(pxpy)). \n",
    "\n",
    "Both $\\tilde{S}^{(n,2)}$ and $S^{(n,2)}$ are 3D tensors with K1 2D slices; as a result of the unpooling, the 2D slices in the sparse $S^{(n,2)}$ have $pxpy$ times more elements than the corresponding slices in the dense $\\tilde{S}^{(n,2)}$.\n",
    "\n",
    "I tried to illustrate what is I believe is happening below:\n",
    "\n",
    "<img src=\"./images/figure1.jpg\" width=\"600\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "def unpool(S, prob_vecs):\n",
    "    \"\"\"\n",
    "    Performs stochastic unpooling on S where the location of the non zero element in each pooling block (i, j)\n",
    "    in layer k is defined by z^k (i, j), and z^k, (i, j) \n",
    "    is sampled from a multinomial distribution Mult(1, prob_vecs(k, i, j)).\n",
    "    \n",
    "    Initially, each prob_vec = (1/(pxpy), ... 1/(pxpy)), i.e the prior distribution. \n",
    "    \n",
    "    The shape of each prob_vec must be pool_size**2. Here we are assuming that our pooling blocks\n",
    "    will always be square.\n",
    "    \n",
    "    S: 3D tensor with the shape (KL, cW, cH)\n",
    "    \n",
    "    prob_vecs: 4D tensor with the shape (KL, cW, cH, pool_size**2):\n",
    "        pool size: px * py\n",
    "    \"\"\"\n",
    "    \n",
    "    K, w, h = S.shape\n",
    "    pool_size = int(math.sqrt(prob_vecs.shape[3])) # We are assuming that the pooling blocks are square.\n",
    "    \n",
    "    result = torch.zeros(K, w*pool_size, h*pool_size)\n",
    "    for k in range(K):\n",
    "        for block in itertools.product(range(w), range(h)):\n",
    "            i, j = block\n",
    "            z = torch.zeros(pool_size**2)\n",
    "            idz = torch.multinomial(prob_vecs[k, i, j], 1).item()\n",
    "            z[idz] = S[k, i, j]\n",
    "            result[k, i*pool_size:(i+1)*pool_size, j*pool_size:(j+1)*pool_size] = z.reshape(-1, pool_size)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While implementing the loss, I believe I misunderstood the unpooling process. I was under the impression that the encoding and decoding layer simply shared _distributions_ , where in fact they share _z_ itself. I.e we only perform sampling in the encoder's pooling layer, and we reuse those samples in the unpooling layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpool(S, z, pool_size):\n",
    "    \"\"\"\n",
    "    Performs stochastic unpooling on S where the location of the non zero element in each pooling block (i, j)\n",
    "    in layer k is defined by z(i, j)^k.\n",
    "    \n",
    "    S: 3D tensor with the shape (KL, cW, cH)\n",
    "    z: 3D tensor with the shape (KL, cW, cH)\n",
    "        Each value in z ranges from 0 inclusive to pool_size**2 exclusive.\n",
    "        \n",
    "        \n",
    "    \"\"\"\n",
    "    K, w, h = S.shape\n",
    "    result = torch.zeros(K, w*pool_size, h*pool_size)\n",
    "    \n",
    "#     for k in range(K):\n",
    "#         for block in itertools.product(range(w), range(h)):\n",
    "#             i, j = block\n",
    "#             unpool_block = torch.zeros(pool_size**2)\n",
    "# #             idz = torch.multinomial(prob_vecs[k, i, j], 1).item()\n",
    "#             idz = z[k, i, j]\n",
    "#             unpool_block[idz] = S[k, i, j]\n",
    "#             result[k, i*pool_size:(i+1)*pool_size, j*pool_size:(j+1)*pool_size] = unpool_block.reshape(-1, pool_size)\n",
    "            \n",
    "    \n",
    "    for block in itertools.product(range(w), range(h)):\n",
    "        i, j = block\n",
    "        unpool_block = torch.zeros(K, pool_size**2)\n",
    "        idz = z[np.arange(K), i, j]\n",
    "        unpool_block[np.arange(K), idz] = S[np.arange(K), i, j]\n",
    "        result[np.arange(K), i*pool_size:(i+1)*pool_size, j*pool_size:(j+1)*pool_size] = \\\n",
    "        unpool_block.reshape(K, -1, pool_size)\n",
    "    \n",
    "    return result\n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "With these two functions, we can implement the DDGM. For the data generation layer, I used the trick described in \n",
    "[this article](https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73). \n",
    "\n",
    "$$X^{(n)} \\sim \\mathcal{N}(\\tilde{S}^{(n, 1)}, \\alpha_0^{-1} \\textbf{I})$$\n",
    "\n",
    "can be expressed as: \n",
    "\n",
    "$$X^{(n)} = \\tilde{S}^{(n, 1)} + \\alpha_0^{-1} Z $$\n",
    "\n",
    "Where $Z \\sim \\mathcal{N}(\\textbf{0}, \\textbf{I})$ due to the linearity of gaussian distributions. This allows backprop to \"reach\" the dictionary layers as we seperate the random process. I believe this is called a 'reparameterization trick'\n",
    "\n",
    "Note that we are storing the $log \\alpha_0$ to ensure that the precision will always be positive.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "class DDGMDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A 2 layered DDGM decoder, with a stochastic unpooling layer between the two layers,\n",
    "    and a final data generation layer. \n",
    "    \"\"\"\n",
    "    def __init__(self, K2, K1, Nc, d2_kernel, d1_kernel, iW, iH, pool_size=3):\n",
    "        \"\"\"\n",
    "        d2 is of shape (K1, K2, kW, kH)\n",
    "            K1: Number of \"slices\" in layer 1\n",
    "            K2: Number of \"slices\" in layer 2\n",
    "            kW, kH: kernel width, kernel height\n",
    "            \n",
    "        d1 is of shape(Nc, K1, kW, kH):\n",
    "            Nc: Number of channels of the image (1 for grayscale, 3 for rgb)\n",
    "            K1: Number of \"slices\" in layer 1\n",
    "            kW, kH: kernel width, kernel height\n",
    "            \n",
    "        distribution is of shape (iW, iH, pool_size**2):\n",
    "            iW, iW: input width, input height\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        self._d2 = nn.Parameter(torch.Tensor(K1, K2, d2_kernel, d2_kernel))\n",
    "        self._d1 = nn.Parameter(torch.Tensor(Nc, K1, d1_kernel, d1_kernel))\n",
    "        self._pool_size = pool_size\n",
    "        \n",
    "        # See above for my misunderstanding\n",
    "        \n",
    "        # Uniformly distributed, equal to 1/pxpy, 1/pxpy... \n",
    "        # self._distribution = torch.ones(K1, iW, iH, pool_size**2) \n",
    "        \n",
    "        self._precision = nn.Parameter(torch.rand(1))\n",
    "        self._reset_parameters()\n",
    "        \n",
    "    # Initialization method is taken from the pytorch implementation of CNNs. \n",
    "    # https://pytorch.org/docs/stable/_modules/torch/nn/modules/conv.html#Conv2d\n",
    "    \n",
    "    def _reset_parameters(self):\n",
    "        init.kaiming_uniform_(self._d2, a=math.sqrt(5))\n",
    "        init.kaiming_uniform_(self._d1, a=math.sqrt(5))\n",
    "        \n",
    "    def get_precision(self):\n",
    "        return self._precision\n",
    "        \n",
    "    def forward(self, x, z):\n",
    "        \"\"\"\n",
    "        X: code generated from encoder\n",
    "            Shape: (K2, iW, iH)\n",
    "        \n",
    "        z: Unpooling map generated from the encoder.\n",
    "            Shape: (K2, iW, iH)\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        S2 = DDGM_convolve(self._d2, x)\n",
    "        S1 = unpool(S2, z, self._pool_size)\n",
    "#         x = unpool(x, self._distribution)\n",
    "        S1 = DDGM_convolve(self._d1, S1)\n",
    "        \n",
    "        # Data Generation\n",
    "        Z = MultivariateNormal(torch.zeros(S1.shape[1]*S1.shape[2]), torch.eye(S1.shape[1]*S1.shape[2]))\n",
    "        slices = []\n",
    "        for k in range(S1.shape[0]):\n",
    "            mean = S1[k, ...].reshape(-1)\n",
    "            \n",
    "            \n",
    "            covar = (1/(torch.exp(self._precision) ** 0.5))*(Z.sample())\n",
    "            slice_ = (mean + covar).reshape(S1.shape[1], -1)\n",
    "            slices.append(slice_)\n",
    "            \n",
    "        # See loss on why we return S1\n",
    "        return torch.stack(slices), S1\n",
    "    \n",
    "#     def set_distribution(self, distribution):\n",
    "#         \"\"\"\n",
    "#         Sets the distribution for stochastic unpooling.\n",
    "#         \"\"\"\n",
    "#         self._distribution = distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "ddgm = DDGMDecoder(K2 = 6, K1 = 4, Nc = 3, d2_kernel=3, d1_kernel=3, iW=10, iH=10)\n",
    "# ddgm(torch.rand(6, 10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "###  Image Encoder: Deep CNN\n",
    "\n",
    "For the encoder, we can employ pytorch's conv2d modules as they perform the convolution that we need, and thus we do not need to define our own convolution method as we did above. However, we do need to create our own pooling function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "def pool(C, prob_vecs, pool_size):\n",
    "    \"\"\"\n",
    "    Performs stochastic pooling on C, where the location of the element chosen in each pooling block (i, j)\n",
    "    in layer kis determined by z^k (i, j), and z(i, j) is sampled from a \n",
    "    multinomial distribution(1, prob_vecs[k, i, j]), and prob_vecs[k, i, j] is derived from \n",
    "    MLP(C^k (i, j)). \n",
    "    \n",
    "    \n",
    "    C is of size (Kl, iW, iH):\n",
    "        KL: Number of 2D \"slices\". \n",
    "        iW, iH: image width, image height. \n",
    "        \n",
    "    Returns: \n",
    "        Result: The result of the pooling. \n",
    "        z: The pooling map generated.\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    K, w, h = C.shape\n",
    "    w_new, h_new = w//pool_size, h//pool_size\n",
    "    result = torch.zeros(K, w_new, h_new)\n",
    "    z = torch.zeros(K, w_new, h_new).type(torch.LongTensor)\n",
    "    \n",
    "#     for k in range(K):\n",
    "#         for block in itertools.product(range(w_new), range(h_new)):\n",
    "#             i, j = block\n",
    "    \n",
    "#             idz = torch.multinomial(prob_vecs[k, i, j], 1).item()\n",
    "#             C_block = C[k, i*pool_size:(i+1)*pool_size, j*pool_size:(j+1)*pool_size].reshape(-1)\n",
    "# #             prob_vec = F.softmax(mlp(C_block), dim=-1)\n",
    "# #             idz = torch.multinomial(prob_vec, 1).item()\n",
    "            \n",
    "#             result[k, i, j] = C_block[idz]\n",
    "#             z[k, i, j] = idz\n",
    "\n",
    "    for block in itertools.product(range(w_new), range(h_new)):\n",
    "        i, j = block\n",
    "        idzs = torch.multinomial(prob_vecs[np.arange(K), i, j], 1).reshape(-1)\n",
    "        C_blocks = C[np.arange(K), i*pool_size:(i+1)*pool_size, j*pool_size:(j+1)*pool_size].reshape(K, -1)\n",
    "        result[np.arange(K), i, j] = C_blocks[np.arange(K), idzs]\n",
    "        z[np.arange(K), i, j] = idzs\n",
    "        \n",
    "    return result, z\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "class CNNEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A 2 layered CNN encoder, with a stochasting pooling layer between the two layers,\n",
    "    and a final code generation layer.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, Nc, K1, K2, f1_kernel, f2_kernel, iW, iH, pool_size=3):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        K1: Number of \"slices\" in layer 1\n",
    "        K2: Number of \"slices\" in layer 2\n",
    "        Nc: Number of channels of the image (1 for grayscale, 3 for rgb)\n",
    "        iW, iW: input width, input height\n",
    "        f1_kernel and f2_kernel: Size of the kernels for each of the filter banks.\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Conv2d(Nc, K1, kernel_size=f1_kernel, padding=(f1_kernel-1)//2, bias=False)\n",
    "        self.layer2 = nn.Conv2d(K1, K2, kernel_size=f2_kernel, padding=(f2_kernel-1)//2, bias=False)\n",
    "        \n",
    "        # MLP for distribution of stochastic pooling\n",
    "        self.mlp_pool = nn.Sequential(\n",
    "            nn.Linear(pool_size**2, 20), # 20 is randomly chosen here.\n",
    "            nn.Tanh(), \n",
    "            nn.Linear(20, pool_size**2)\n",
    "        )\n",
    "        \n",
    "        self.mlp_shared = nn.Sequential(\n",
    "            nn.Linear((iW//pool_size) * (iH//pool_size), 20),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.mlp_mean = nn.Linear(20, (iW//pool_size) * (iH//pool_size))\n",
    "        self.mlp_covar = nn.Linear(20, (iW//pool_size) * (iH//pool_size))\n",
    "        \n",
    "        \n",
    "#         # MLP for code generation mean \n",
    "#         self.mlp_mean = nn.Sequential(\n",
    "#             nn.Linear((iW//pool_size) * (iH//pool_size), 20),\n",
    "#             nn.Tanh(), \n",
    "#             nn.Linear(20, (iW//pool_size) * (iH//pool_size))\n",
    "#         )\n",
    "        \n",
    "#         # MLP for code generation covariance \n",
    "#         self.mlp_covar = nn.Sequential(\n",
    "#             nn.Linear((iW//pool_size) * (iH//pool_size), 20),\n",
    "#             nn.Tanh(), \n",
    "#             nn.Linear(20, (iW//pool_size) * (iH//pool_size))\n",
    "#         )\n",
    "        \n",
    "        self._pool_size = pool_size\n",
    "        \n",
    "    def get_distribution(self, C):\n",
    "        \"\"\"\n",
    "        Gets all the distributions for pooling, i.e the vector softmax(eta). \n",
    "        This distribution will be reused as the posterior for the decoder's unpooling as well.\n",
    "        \"\"\"\n",
    "        K, w, h = C.shape\n",
    "        pool_size = self._pool_size\n",
    "        w_new, h_new = w // pool_size, h // pool_size\n",
    "      \n",
    "        result = torch.zeros(K, w_new, h_new, self._pool_size**2)\n",
    "        for k in range(K):\n",
    "            for block in itertools.product(range(w_new), range(h_new)):\n",
    "                i, j = block\n",
    "                C_block = C[k, i*pool_size:(i+1)*pool_size, j*pool_size:(j+1)*pool_size].reshape(-1)\n",
    "                eta = self.mlp_pool(C_block)\n",
    "                prob_vec = F.softmax(eta, dim=-1)\n",
    "                result[k, i, j, :] = prob_vec\n",
    "                \n",
    "        return result\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: Input image\n",
    "            Shape: (Nc, iW, iH)\n",
    "        \"\"\"\n",
    "        \n",
    "        C1 = self.layer1(x.unsqueeze(0))\n",
    "        distribution = self.get_distribution(C1.squeeze(0))\n",
    "        \n",
    "        C1, z = pool(C1.squeeze(0), distribution, self._pool_size)\n",
    "        C2 = self.layer2(C1.unsqueeze(0))\n",
    "        C2 = C2.squeeze(0)\n",
    "        \n",
    "        # Final Code generation\n",
    "        slices = []\n",
    "        means = []\n",
    "        covars = []\n",
    "        Z = MultivariateNormal(torch.zeros(C2.shape[1]*C2.shape[2]), torch.eye(C2.shape[1]*C2.shape[2]))\n",
    "        for k in range(C2.shape[0]):\n",
    "            hidden = self.mlp_shared(C2[k, ...].reshape(-1))\n",
    "            \n",
    "            mean = self.mlp_mean(hidden)\n",
    "            original_covar = self.mlp_covar(hidden)\n",
    "            \n",
    "            # Why are we doing exp here? In the supplementary paper (section 4), it is described that \n",
    "            # log sigma is created with the mlp, and therefore we need to perform exp() to get sigma.\n",
    "            \n",
    "            covar = torch.exp(torch.diag(original_covar)) @ Z.sample()\n",
    "            slice_ = (mean + covar).reshape(C2.shape[1], -1)\n",
    "            slices.append(slice_)\n",
    "            means.append(mean)\n",
    "            covars.append(original_covar)\n",
    "    \n",
    "        return torch.stack(slices), z, distribution, torch.stack(means), torch.stack(covars)\n",
    "        # (s, z, eta, mu, sigma)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 10, 10]),\n",
       " torch.Size([4, 10, 10]),\n",
       " torch.Size([4, 10, 10, 9]),\n",
       " torch.Size([6, 100]),\n",
       " torch.Size([6, 100]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = CNNEncoder(3, 4, 6, 3, 3, 32, 32)\n",
    "s, z, eta, mu, sigma = encoder(torch.rand(3, 32, 32))\n",
    "s.shape, z.shape, eta.shape, mu.shape, sigma.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting the VAE together\n",
    "\n",
    "Finally, we can piece the encoder and decoder together to form the VAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    \n",
    "    def __init__(self, Nc, K1, K2, f1, f2, d2, d1, iW, iH, pool_size=3):\n",
    "        \"\"\"\n",
    "        Nc: Number of channels of the image. \n",
    "        K1: Number of 2D \"slices\" in layer 1. This is shared for the encoder and decoder.\n",
    "        K2: Number of 2D \"slices\" in layer 2. This is shared for the encoder and decoder. \n",
    "        f1, f2: Kernel size for the first and second filter bank respectively\n",
    "        d2, d1: Kernel size for the second and first dictionary respectively. \n",
    "        iW, iH: width and height of the image. \n",
    "        pool_size: The size of the pooling block. We are assuming that pooling blocks are square.\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        self.encoder = CNNEncoder(Nc, K1, K2, f1, f2, iW, iH, pool_size)\n",
    "        cW, cH = iW // pool_size, iH // pool_size # code width, code height\n",
    "        self.decoder = DDGMDecoder(K2, K1, Nc, d2, d1, cW, cH, pool_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: Input image\n",
    "            Shape: (Nc, iW, iH)\n",
    "        \"\"\"\n",
    "        \n",
    "        s, z, eta, mu, sigma = self.encoder(x)\n",
    "        z = z.type(torch.LongTensor)\n",
    "        x_reconstructed, mu_decoder = self.decoder(s, z)\n",
    "        \n",
    "        \n",
    "        return x_reconstructed, mu, sigma, eta, mu_decoder, self.decoder.get_precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 4.6889e-01,  4.7135e-01,  4.6170e-01,  ..., -3.9289e-01,\n",
       "           -5.2799e-01,  1.9867e+00],\n",
       "          [ 4.7092e-02, -1.4013e-01,  1.0758e+00,  ..., -7.6817e-01,\n",
       "            3.3951e+00, -1.2391e+00],\n",
       "          [-2.8409e-01,  2.4358e-01,  3.5475e+00,  ..., -9.9530e-01,\n",
       "           -2.9900e-01, -5.6686e-01],\n",
       "          ...,\n",
       "          [-4.8911e-01,  1.1520e+00, -1.2597e+00,  ...,  7.4309e-01,\n",
       "            6.4519e-01, -1.0471e+00],\n",
       "          [ 8.8405e-01, -3.4708e-02,  1.6469e+00,  ...,  3.3507e-01,\n",
       "            1.2498e+00,  8.1827e-01],\n",
       "          [-2.0065e+00,  7.3398e-01,  7.3541e-01,  ..., -1.2976e+00,\n",
       "           -7.7838e-01, -1.4494e+00]],\n",
       " \n",
       "         [[ 5.5157e-01, -1.3644e+00, -1.8632e-01,  ...,  4.6139e-01,\n",
       "            4.3517e-02,  3.1379e+00],\n",
       "          [ 1.0561e+00,  1.1640e+00,  1.1687e+00,  ..., -2.0753e+00,\n",
       "            2.8717e-02, -2.3281e+00],\n",
       "          [-2.0406e-01,  1.1991e+00,  1.5456e+00,  ..., -9.9895e-01,\n",
       "            8.1266e-01, -2.7303e+00],\n",
       "          ...,\n",
       "          [-1.2828e+00, -9.6146e-01,  1.2296e+00,  ..., -3.7791e-01,\n",
       "            1.3882e+00, -3.8318e-01],\n",
       "          [-3.5440e-01,  1.0352e+00,  2.9053e+00,  ...,  8.2317e-01,\n",
       "            8.6514e-01,  1.4968e+00],\n",
       "          [ 5.9550e-03,  1.2457e+00,  8.3231e-01,  ..., -8.7219e-01,\n",
       "           -5.9295e-04, -2.1838e+00]],\n",
       " \n",
       "         [[ 2.0188e+00, -1.1243e-01,  1.1614e+00,  ...,  7.1220e-01,\n",
       "            8.3558e-01,  2.6023e+00],\n",
       "          [ 1.8787e+00,  6.7309e-02,  4.0066e-01,  ..., -1.4902e-01,\n",
       "            1.7695e+00,  1.0039e+00],\n",
       "          [ 1.4371e+00,  2.6849e+00,  1.1255e+00,  ...,  8.2640e-01,\n",
       "           -7.2851e-01,  7.2631e-02],\n",
       "          ...,\n",
       "          [ 2.8313e+00,  5.1091e-01,  1.1106e+00,  ...,  2.5784e+00,\n",
       "            1.3548e+00,  1.7194e+00],\n",
       "          [ 1.5346e+00,  4.1715e-01,  2.2392e+00,  ...,  6.8823e-01,\n",
       "           -1.0841e+00, -7.9909e-01],\n",
       "          [ 1.3669e+00, -7.8035e-02,  1.8283e+00,  ..., -8.8189e-01,\n",
       "           -5.4686e-01, -5.5138e-01]]], grad_fn=<StackBackward>),\n",
       " tensor([[ 1.4665e-01,  3.8498e-01,  1.5375e-01, -2.6146e-02, -2.8543e-01,\n",
       "           5.5162e-02, -1.5745e-01, -8.2540e-02,  3.4869e-02,  4.9110e-02,\n",
       "          -1.0731e-01,  2.0516e-01,  2.5331e-02, -2.2782e-01,  3.2771e-02,\n",
       "           1.9416e-01,  1.0553e-02, -4.4407e-02,  2.6012e-01,  2.6162e-03,\n",
       "          -1.1417e-01, -1.2821e-01, -1.7779e-01,  2.9337e-02,  1.3599e-02,\n",
       "           8.8061e-02, -1.0185e-01, -1.6976e-01,  9.4785e-02,  7.7833e-02,\n",
       "           9.2698e-02, -8.8307e-02, -1.1630e-01, -1.1005e-01, -2.7869e-01,\n",
       "           4.2705e-02, -9.1598e-02,  6.0989e-02,  6.8087e-02,  2.9422e-01,\n",
       "          -2.1553e-01,  9.9623e-03, -2.1872e-01,  6.6425e-02, -1.7176e-01,\n",
       "          -1.2301e-01, -1.9545e-02, -2.3989e-01,  6.5221e-02, -1.1000e-01,\n",
       "           1.6671e-01, -2.3027e-01, -8.5409e-02,  1.4109e-01,  4.8845e-02,\n",
       "          -7.4618e-02, -2.0939e-01,  6.2148e-02,  1.6654e-02, -8.9558e-02,\n",
       "          -7.1226e-02,  2.3344e-01, -5.9387e-02,  1.7367e-01,  8.6571e-02,\n",
       "          -1.5891e-01, -1.3238e-01,  8.3417e-02,  5.3833e-02,  1.6586e-01,\n",
       "          -1.0657e-01,  9.2388e-02, -2.4741e-01, -2.4889e-01,  1.2546e-01,\n",
       "           3.3461e-02, -5.8042e-02, -5.2574e-02, -2.0443e-01, -9.7526e-02,\n",
       "          -1.6839e-01, -5.2203e-02,  1.5732e-01,  9.9644e-02,  7.6075e-03,\n",
       "           5.8430e-02,  5.4984e-02, -3.6795e-01,  1.6166e-01,  1.5825e-01,\n",
       "          -2.1863e-01, -1.6074e-01,  1.5657e-02, -8.9953e-02, -6.6116e-02,\n",
       "          -1.1108e-02, -1.1287e-01,  2.3403e-01,  1.6115e-01, -1.0900e-01],\n",
       "         [ 4.2125e-01,  1.1827e-01,  6.5339e-02, -8.8415e-02, -1.7288e-01,\n",
       "           2.1443e-01, -7.9094e-02, -3.8540e-01, -2.1934e-02,  1.8328e-03,\n",
       "           1.4769e-01, -8.0828e-02,  2.4344e-01,  2.1286e-01, -1.4796e-01,\n",
       "          -1.3004e-02,  1.8135e-01,  2.7624e-01,  2.0995e-01, -3.3918e-02,\n",
       "          -1.0793e-01, -1.7953e-01, -2.1430e-01, -3.0486e-01,  2.1170e-01,\n",
       "           1.3039e-01,  9.8941e-03,  8.3641e-02,  2.0911e-01, -1.6584e-01,\n",
       "           1.1646e-02, -2.6594e-01,  1.1421e-01,  4.9645e-02, -1.2979e-01,\n",
       "          -8.9179e-02,  9.7183e-02, -3.7731e-02,  1.6252e-01,  1.9830e-01,\n",
       "          -1.4450e-01,  1.8032e-01, -1.8772e-01,  2.5817e-04, -1.5181e-01,\n",
       "           1.0787e-01,  1.0390e-01, -2.1849e-01,  1.5245e-01, -7.1109e-02,\n",
       "           6.9663e-03, -4.7107e-02, -1.0403e-01, -1.7362e-01,  1.3462e-01,\n",
       "          -2.5809e-01,  1.2402e-01, -4.0697e-03,  1.5774e-01, -1.6274e-01,\n",
       "           1.1185e-01, -2.0998e-01, -1.5585e-01,  1.3369e-01, -1.4380e-01,\n",
       "           3.1876e-02, -9.7368e-02,  2.3929e-01, -2.1698e-02,  1.1255e-01,\n",
       "          -5.2835e-02,  2.6715e-02, -9.5176e-02,  5.8877e-03,  2.3003e-01,\n",
       "          -7.7236e-03,  2.2460e-02, -5.4015e-03,  6.6931e-02, -9.2060e-02,\n",
       "          -1.3487e-01, -1.1184e-01,  2.8245e-01,  2.5551e-02, -1.0172e-02,\n",
       "          -9.6548e-02, -2.1975e-01, -2.5667e-01,  5.0449e-02,  2.0845e-01,\n",
       "          -1.3134e-01, -3.2258e-02,  3.0152e-02, -7.1800e-02,  1.2819e-01,\n",
       "          -1.7579e-01, -4.2461e-02,  1.4989e-01,  5.0180e-02,  2.1191e-01],\n",
       "         [ 6.6228e-02,  3.1736e-01,  8.9901e-02,  1.0145e-01, -4.0319e-01,\n",
       "           1.1519e-01, -8.9468e-02, -2.9768e-01,  1.4902e-01, -1.1015e-01,\n",
       "           1.4812e-01, -1.5562e-01, -7.3597e-02, -1.5549e-02, -7.4898e-02,\n",
       "           2.7302e-01, -1.5681e-01,  1.2218e-01,  5.5964e-02, -1.6090e-01,\n",
       "           3.5080e-02, -3.4694e-01, -2.5528e-01, -2.6762e-01,  1.6906e-01,\n",
       "           6.3359e-02, -3.4231e-01, -5.7008e-02,  1.5344e-01, -2.4187e-01,\n",
       "           6.9948e-02, -1.8162e-01, -2.7441e-01, -1.8829e-01, -2.5939e-01,\n",
       "          -3.4703e-02, -3.4761e-03, -5.7137e-02,  7.5061e-02,  1.4193e-01,\n",
       "          -1.5744e-01,  3.6598e-02, -2.4201e-01,  3.9663e-01, -3.3061e-01,\n",
       "          -1.6695e-01, -3.5035e-02, -4.4538e-03,  2.1739e-02, -9.4056e-02,\n",
       "           1.5787e-01, -3.4589e-02,  1.0377e-01,  9.7359e-02, -6.7079e-03,\n",
       "           1.8546e-01, -3.9952e-02, -8.5949e-02,  6.8380e-02, -7.5316e-02,\n",
       "           9.4933e-02,  6.3572e-02, -3.7084e-02,  2.8326e-01, -4.1870e-02,\n",
       "          -3.8063e-01, -5.3497e-02, -7.4095e-02,  9.2724e-02,  9.9877e-02,\n",
       "           7.0402e-02,  3.3026e-01, -2.4406e-01, -4.4738e-01,  3.5031e-01,\n",
       "          -7.2977e-02,  5.9540e-02, -1.2171e-02, -2.6514e-02, -8.0111e-02,\n",
       "          -6.8432e-02, -1.0595e-01,  1.6107e-01,  2.5450e-02,  4.9277e-02,\n",
       "          -4.6085e-02, -8.3894e-02, -4.1403e-01,  2.5467e-01, -1.1686e-01,\n",
       "          -2.1009e-01, -1.9053e-01,  4.2402e-02, -7.9926e-02,  6.2730e-02,\n",
       "           4.5094e-02, -8.7988e-02,  2.5355e-01,  4.2617e-02,  6.8906e-02],\n",
       "         [ 3.0317e-01,  1.2171e-01, -1.3527e-01,  9.9088e-03, -4.2265e-01,\n",
       "           2.2175e-01,  8.9164e-02, -1.7651e-01,  3.6807e-01, -5.8632e-02,\n",
       "           1.2294e-01,  2.1580e-01,  9.0914e-02, -1.6417e-01, -1.4502e-01,\n",
       "           3.3009e-01,  1.6688e-01,  2.3830e-02,  2.7790e-01,  3.9647e-02,\n",
       "          -2.8695e-01, -9.3526e-02, -5.3273e-03, -2.0828e-01,  3.4924e-01,\n",
       "           1.9065e-01, -1.3846e-02, -1.2310e-01,  1.4495e-01, -1.1550e-01,\n",
       "           5.7299e-02, -5.2622e-02, -6.7467e-02, -4.6900e-02, -1.0269e-01,\n",
       "           2.6146e-01, -1.6043e-01,  3.0788e-02,  3.5395e-01,  2.3151e-02,\n",
       "          -6.0117e-02,  1.5254e-01, -1.5203e-01, -6.1517e-02, -2.5905e-01,\n",
       "          -1.4448e-01,  2.0770e-01, -9.5940e-02,  6.2124e-02,  2.7458e-02,\n",
       "          -1.8821e-01, -1.2652e-01, -4.4186e-02,  1.5303e-01,  8.9269e-02,\n",
       "          -1.0990e-01,  2.7511e-02,  1.4273e-01,  4.3714e-02, -5.9008e-02,\n",
       "           1.7311e-01,  2.9042e-03, -1.5855e-01,  1.7359e-01, -9.2887e-02,\n",
       "          -1.6942e-03,  1.7744e-02,  1.5760e-01, -6.4987e-02,  3.0837e-01,\n",
       "          -2.5818e-01,  1.4315e-01, -3.4572e-01, -2.8285e-01,  1.6779e-01,\n",
       "          -2.5211e-02,  9.1334e-02,  1.1064e-01, -1.4880e-02, -3.3849e-01,\n",
       "          -2.7166e-01,  1.5770e-02,  5.0374e-02, -5.3965e-02, -2.2982e-01,\n",
       "           1.2227e-02, -7.0873e-02, -1.7654e-01,  3.1091e-03,  7.8538e-02,\n",
       "           6.2306e-02, -1.9704e-01,  6.4148e-02, -1.9207e-01, -8.0229e-02,\n",
       "          -1.8720e-02,  8.4644e-02,  2.6876e-01,  2.5629e-01, -1.0570e-01],\n",
       "         [ 6.6823e-02,  8.8558e-02,  1.6812e-01,  1.5174e-01, -4.1775e-01,\n",
       "           7.6638e-02, -2.6084e-01, -2.5986e-01,  1.3876e-01, -3.0210e-02,\n",
       "           8.9772e-02,  2.2129e-02,  1.8011e-02, -9.1701e-02, -1.5979e-01,\n",
       "           1.1730e-01, -8.2924e-03, -2.4969e-02,  2.6420e-01,  2.6321e-02,\n",
       "          -1.0529e-01, -1.2961e-01, -9.9797e-02, -7.8261e-02,  1.6539e-01,\n",
       "           1.2559e-01, -1.2950e-01, -1.7006e-01,  2.2879e-01, -9.4661e-02,\n",
       "           1.2306e-01, -2.1630e-01, -1.3183e-01, -1.6093e-01, -1.5796e-01,\n",
       "          -8.2932e-02,  1.1074e-01,  8.9353e-02,  1.4858e-01,  1.2781e-01,\n",
       "          -1.8926e-01,  3.8274e-02, -9.2856e-02,  2.1933e-01, -2.7434e-01,\n",
       "          -2.9440e-01,  3.3337e-02, -7.0056e-02,  5.6597e-02, -1.1669e-01,\n",
       "           1.4299e-01, -2.8406e-01, -2.8595e-02,  4.6449e-02,  3.4659e-02,\n",
       "          -6.9237e-02, -1.3334e-01,  9.9436e-02, -1.3835e-02, -7.4281e-02,\n",
       "           1.1205e-01,  2.8764e-02, -1.4215e-01,  8.6364e-02, -1.2549e-01,\n",
       "          -2.5617e-01, -1.1230e-01,  5.2687e-02,  2.6029e-03,  3.1248e-01,\n",
       "          -8.1271e-02,  4.5774e-02, -3.9147e-01, -2.9489e-01,  2.5030e-01,\n",
       "           7.2426e-02,  7.8262e-02,  8.7432e-03, -1.9925e-02, -2.0887e-01,\n",
       "          -9.2780e-02, -1.9064e-03,  1.5775e-01,  3.9310e-02, -4.9361e-02,\n",
       "           8.8315e-02, -1.8379e-02, -2.1858e-01,  9.6974e-02, -5.6303e-02,\n",
       "          -1.5408e-01, -1.3241e-01,  6.8369e-02,  1.1184e-02, -3.1194e-02,\n",
       "          -3.1130e-02,  4.6365e-02,  2.3576e-01,  6.7855e-02, -1.9112e-01],\n",
       "         [ 2.1897e-01,  2.3401e-01,  1.8179e-01,  6.5435e-02, -2.5987e-01,\n",
       "           6.0424e-02, -2.3945e-01, -3.1807e-01,  1.3119e-01, -1.0638e-01,\n",
       "           1.0163e-01, -9.4006e-02,  1.3264e-01, -3.9155e-02, -2.8422e-01,\n",
       "           2.9926e-01,  1.0933e-01,  6.1722e-02,  1.5175e-01, -1.1266e-03,\n",
       "          -2.2240e-02, -2.4207e-01, -1.9086e-01, -1.7806e-01,  8.6604e-02,\n",
       "           1.4970e-01,  5.4946e-02, -3.1029e-01,  2.1143e-01, -2.5439e-01,\n",
       "           7.7397e-02, -2.1492e-01, -1.2838e-01, -4.3751e-02, -4.2337e-02,\n",
       "          -1.7466e-03, -9.1431e-03, -7.2019e-02,  1.2449e-01, -7.2576e-03,\n",
       "          -5.8446e-02, -8.1079e-03, -1.4079e-01,  1.4804e-01, -2.4249e-01,\n",
       "          -3.1708e-01,  4.5226e-02, -3.3353e-02,  3.1197e-01,  6.1945e-02,\n",
       "           1.9285e-01, -1.0346e-01,  8.5070e-02, -2.6125e-02,  1.2904e-01,\n",
       "          -4.1282e-03, -1.0841e-01, -3.8404e-02,  3.5732e-03, -2.2180e-02,\n",
       "          -1.9683e-02, -7.3999e-02, -1.2084e-01,  9.4685e-02, -1.3747e-01,\n",
       "          -2.8482e-01, -1.0713e-01, -3.6755e-02,  1.6675e-01,  2.0304e-01,\n",
       "          -6.8625e-02,  9.5912e-02, -2.7901e-01, -2.4560e-01,  2.3265e-01,\n",
       "          -6.6146e-02,  1.0717e-02, -1.6212e-01, -4.6738e-02, -1.3223e-01,\n",
       "          -6.3752e-02, -1.6058e-01,  1.1650e-01,  1.3249e-01, -5.0125e-02,\n",
       "           1.0869e-01, -4.1592e-02, -2.6775e-01,  1.9413e-01, -1.0181e-02,\n",
       "          -2.7859e-01,  6.0972e-02,  7.0284e-03, -4.3242e-02,  4.7235e-03,\n",
       "           1.9251e-02, -1.2691e-01,  1.6305e-01,  6.5394e-02, -3.3513e-02]],\n",
       "        grad_fn=<StackBackward>),\n",
       " tensor([[ 2.5315e-01,  1.1337e-01, -6.2043e-02, -2.0864e-01,  3.4784e-01,\n",
       "           5.8781e-02,  2.2149e-01,  4.6625e-01,  3.3004e-01,  8.5628e-02,\n",
       "           1.5592e-01, -2.3074e-01, -2.0122e-01, -5.0525e-02, -1.4956e-01,\n",
       "           2.3747e-01,  8.3911e-02, -2.9552e-02,  2.6194e-01,  4.1665e-01,\n",
       "          -2.9693e-01, -1.3913e-01,  7.0770e-02,  6.2268e-02,  5.1359e-02,\n",
       "          -5.0378e-02, -1.9286e-01, -1.3027e-01,  6.0680e-02,  1.2629e-01,\n",
       "           2.3327e-01, -1.0138e-01,  8.8649e-02, -1.2703e-01,  3.3053e-02,\n",
       "          -1.0626e-04,  9.6711e-02, -1.3593e-01,  2.1268e-01, -1.9391e-01,\n",
       "           3.6320e-01,  2.5980e-01, -1.8495e-01, -3.4980e-01, -1.3317e-01,\n",
       "          -1.1556e-01,  4.6723e-02, -2.5434e-01,  6.3604e-02, -4.6513e-03,\n",
       "           1.9212e-01,  3.5316e-02,  3.0066e-01,  1.8868e-01, -1.8120e-02,\n",
       "          -2.1131e-01, -9.3038e-02, -2.7493e-02, -2.0931e-01,  5.3763e-02,\n",
       "          -3.4934e-01, -7.4497e-02,  2.3709e-01, -1.8866e-01, -1.6602e-01,\n",
       "           1.4439e-01, -1.5362e-01, -1.6694e-01, -1.6478e-01, -5.0590e-02,\n",
       "          -4.0032e-01, -2.0123e-01, -5.7409e-02,  5.3076e-02, -1.7409e-01,\n",
       "           5.6440e-02,  2.8179e-02,  2.0138e-02,  7.0553e-02,  1.1110e-01,\n",
       "          -3.4541e-02, -2.5943e-02, -3.8794e-01,  8.8190e-02,  1.3149e-01,\n",
       "          -1.8708e-01,  5.9515e-02, -2.3296e-01,  2.5363e-01,  3.0563e-01,\n",
       "           1.0087e-01,  7.8781e-02, -1.3937e-02,  2.6483e-02, -1.4323e-01,\n",
       "          -1.6298e-01,  1.8831e-01,  1.8053e-01, -1.2866e-01,  8.6626e-03],\n",
       "         [ 5.0907e-02,  5.0431e-02,  2.3103e-03, -5.5721e-02,  3.1032e-02,\n",
       "           4.6991e-01,  1.4779e-01,  5.1563e-02,  2.4251e-01, -1.8836e-01,\n",
       "           2.3902e-01, -1.7131e-01, -2.3774e-01,  2.2789e-01, -5.1314e-02,\n",
       "           1.4275e-01,  9.9217e-02, -2.2126e-02, -9.3888e-03,  8.5079e-02,\n",
       "          -2.5689e-01, -2.0052e-01,  1.5432e-01,  1.5145e-01,  1.3253e-02,\n",
       "           5.9955e-02, -6.1371e-03, -1.6475e-01,  1.1373e-01,  2.5191e-01,\n",
       "           9.4453e-03, -1.4241e-01,  1.1780e-01, -2.1811e-01, -1.0424e-01,\n",
       "           5.9456e-02, -6.6971e-02, -1.7557e-01, -5.1402e-02, -1.3858e-01,\n",
       "           1.9975e-01,  2.8464e-01, -3.6867e-01, -2.0269e-01,  1.2265e-01,\n",
       "          -2.7071e-01,  5.2370e-02, -9.9680e-02, -1.5549e-01,  6.7689e-02,\n",
       "           1.5626e-02, -1.4772e-01,  3.2041e-01,  7.0392e-02, -1.2302e-01,\n",
       "          -1.9602e-01, -3.0009e-02,  5.8170e-02, -4.3683e-01,  1.5958e-01,\n",
       "          -9.4396e-02, -1.4654e-01,  3.7605e-01, -1.0631e-01, -2.2632e-01,\n",
       "           1.6296e-01, -3.1100e-01, -1.5553e-01, -1.2897e-01, -2.0528e-02,\n",
       "          -2.9161e-01, -1.8916e-01, -1.3354e-01, -8.2724e-02, -1.7628e-01,\n",
       "           1.1212e-01,  3.3704e-02, -2.2277e-01,  8.3610e-02,  1.7245e-01,\n",
       "          -2.5603e-02, -7.9053e-02, -2.4617e-01, -1.9134e-01,  1.4239e-01,\n",
       "          -3.0124e-01, -2.1458e-03, -1.8170e-01,  4.1456e-01,  1.9714e-02,\n",
       "           6.2788e-02, -4.6939e-02,  6.7831e-02, -1.7020e-02,  6.3306e-02,\n",
       "           1.9309e-02,  1.3803e-01, -7.7193e-02, -1.3197e-01,  1.2550e-01],\n",
       "         [ 9.6881e-02,  1.9216e-01, -1.5200e-01, -3.0109e-02,  2.7635e-01,\n",
       "           1.9513e-01,  2.6010e-01,  3.8512e-01,  2.0602e-01,  1.6637e-01,\n",
       "           6.0796e-03, -3.4700e-01, -1.6907e-01,  1.2641e-01, -2.4695e-01,\n",
       "           3.0828e-01,  2.3835e-01,  3.4294e-02,  7.5873e-02,  4.0563e-01,\n",
       "          -2.6747e-01, -4.7028e-02,  1.7043e-01,  1.9303e-02,  1.1591e-01,\n",
       "           1.0592e-03, -1.1881e-01,  2.6823e-02,  1.8626e-01,  3.5444e-02,\n",
       "           1.7149e-01, -1.4968e-01, -1.6700e-01, -1.1283e-01,  1.0752e-01,\n",
       "           1.2104e-01,  3.3771e-01, -9.6723e-02,  8.1252e-02, -1.3586e-02,\n",
       "           9.0893e-02,  1.5948e-01, -1.2592e-01, -1.9233e-01,  1.7398e-02,\n",
       "          -8.9158e-02,  9.8373e-02, -2.6306e-01,  4.4755e-02, -1.5376e-01,\n",
       "          -1.1276e-01,  1.3708e-01,  1.3859e-01,  1.3174e-01, -7.3824e-02,\n",
       "          -2.1797e-01,  7.8917e-03, -9.8362e-02, -2.1101e-01,  1.2702e-01,\n",
       "          -2.5886e-01, -1.9764e-01,  1.6926e-01, -1.8064e-01, -3.8698e-01,\n",
       "          -1.1698e-01, -1.3153e-01, -2.8756e-01, -7.6793e-02, -2.6522e-02,\n",
       "          -4.0091e-01, -3.1727e-01,  1.0224e-01,  1.0855e-01, -1.4557e-01,\n",
       "          -5.6217e-02,  1.3859e-01,  7.2106e-02,  1.1701e-01,  2.2634e-01,\n",
       "           3.1543e-02,  9.1537e-02, -3.8046e-01,  8.6044e-02,  8.3588e-02,\n",
       "          -2.5782e-01,  1.9752e-01, -1.9155e-01,  2.0724e-01,  2.6076e-01,\n",
       "           2.2273e-01, -1.6901e-01, -1.1478e-01, -9.7195e-02, -1.4780e-02,\n",
       "          -1.9756e-01,  2.1158e-02,  1.9206e-02,  7.8232e-02, -1.5455e-01],\n",
       "         [ 1.3440e-01, -5.1329e-03,  2.8950e-02,  1.1024e-01,  1.6553e-01,\n",
       "           5.3205e-02,  2.4194e-01,  1.3942e-01,  6.4375e-02,  2.1553e-02,\n",
       "           2.5312e-01,  1.4611e-02, -2.1575e-01, -2.7457e-02,  6.2091e-02,\n",
       "           2.0558e-01,  1.9579e-01, -1.9053e-01,  5.5312e-02,  1.7636e-01,\n",
       "          -1.6344e-01, -2.0383e-01,  1.8049e-01,  2.3521e-01, -9.6605e-02,\n",
       "           1.2182e-01,  9.0008e-02, -1.2088e-01,  1.7787e-01, -8.8943e-02,\n",
       "           2.6014e-01, -2.4217e-01,  6.1615e-02, -7.3336e-02, -1.5329e-01,\n",
       "           2.2100e-01,  8.4411e-02, -2.5507e-01, -3.8579e-02, -3.7766e-03,\n",
       "          -1.2134e-02,  1.0521e-01, -4.7022e-02, -1.7804e-01,  9.0229e-02,\n",
       "          -1.9144e-01,  1.2629e-01, -1.7570e-01, -4.0783e-03, -6.9435e-04,\n",
       "           9.8585e-02, -1.2249e-02,  3.0795e-01,  5.9432e-02,  2.8493e-02,\n",
       "          -8.8114e-02, -1.1142e-01,  1.2312e-02, -2.1098e-01, -7.8610e-02,\n",
       "          -1.1478e-01, -2.6124e-01,  3.3793e-01,  4.7717e-02, -1.8740e-01,\n",
       "          -1.3659e-01,  3.3111e-02, -2.9394e-01, -2.2990e-01, -1.8385e-01,\n",
       "          -3.0068e-01, -2.1438e-01,  1.3532e-02, -1.1547e-02, -9.8879e-02,\n",
       "          -1.4912e-01,  2.0614e-01, -2.0566e-01,  1.9886e-01,  3.0377e-01,\n",
       "           6.7405e-02, -5.9615e-02, -5.0369e-02,  1.0958e-01,  8.8664e-02,\n",
       "          -2.0878e-01,  9.3886e-02,  2.8967e-02,  2.1021e-01,  1.5450e-01,\n",
       "           2.7131e-01,  1.1936e-01, -9.5455e-02,  9.0474e-02, -2.4403e-02,\n",
       "          -9.0431e-03, -4.9584e-02,  1.0923e-01, -1.0091e-01,  1.5313e-01],\n",
       "         [ 1.2255e-01,  1.0892e-01, -6.2995e-02,  2.8532e-02,  3.8144e-01,\n",
       "           6.4442e-02,  2.7077e-01,  2.9595e-01,  1.1445e-01,  1.4315e-01,\n",
       "           1.3829e-01, -2.5381e-01,  2.4237e-03,  1.3940e-02, -6.4495e-02,\n",
       "           1.7349e-01,  1.7014e-01,  1.0250e-02,  2.0851e-01,  2.4521e-01,\n",
       "          -9.7182e-02, -2.3860e-01,  1.2503e-02, -3.3684e-03,  1.6133e-01,\n",
       "           9.6100e-02, -1.4815e-01, -2.3352e-02,  2.3670e-01,  1.7754e-01,\n",
       "           2.7112e-02, -1.4599e-01,  5.5787e-02, -1.9568e-01,  4.7397e-02,\n",
       "          -7.3310e-05,  1.9078e-01, -2.0828e-01,  4.6537e-02, -6.6683e-02,\n",
       "           1.7499e-01,  2.6050e-01, -1.3260e-01, -1.7527e-01,  7.8761e-02,\n",
       "          -1.8284e-01,  1.2488e-01, -1.2247e-01, -4.5442e-02,  5.1519e-02,\n",
       "           1.4470e-01,  4.1497e-02,  5.8059e-02,  1.3415e-01, -7.9048e-02,\n",
       "          -1.9439e-01,  1.3516e-01, -1.0854e-01, -1.4413e-01,  7.5205e-02,\n",
       "          -2.1438e-01, -2.6398e-01,  2.5158e-01, -2.4486e-01, -1.5347e-01,\n",
       "          -1.0907e-01, -1.5917e-01, -1.7386e-01,  2.0460e-02,  2.3210e-02,\n",
       "          -3.8962e-01, -2.0584e-01,  3.7182e-02,  7.8896e-02, -2.6874e-01,\n",
       "           2.1701e-03,  9.0649e-02,  3.7911e-03,  1.9964e-01,  2.8980e-01,\n",
       "           1.3690e-01, -1.2740e-01, -3.4701e-01,  9.8570e-02,  4.6115e-02,\n",
       "          -1.2427e-01,  1.5152e-01, -1.5542e-01,  3.3271e-01,  1.9144e-01,\n",
       "           2.0431e-01, -2.1038e-01, -6.3808e-02, -3.7218e-02, -5.8876e-02,\n",
       "          -1.5525e-01, -3.0994e-02, -9.7192e-02, -8.0288e-03,  8.1209e-02],\n",
       "         [ 9.5419e-02,  3.5855e-02,  2.7008e-02,  7.5734e-02,  1.6148e-01,\n",
       "           2.8608e-01,  1.4476e-01,  3.1967e-01, -9.0393e-03,  2.8940e-02,\n",
       "           2.7513e-01, -2.7389e-01,  2.1334e-02,  1.2150e-01, -4.1267e-02,\n",
       "           2.2820e-01,  1.8311e-01, -9.6983e-02,  1.5045e-01,  2.0480e-01,\n",
       "          -2.3548e-01, -3.5474e-01, -5.1349e-02,  3.2528e-02,  1.1355e-01,\n",
       "           4.6321e-02, -1.0415e-01,  4.1737e-02,  5.7257e-02,  8.1287e-02,\n",
       "           1.1193e-01, -1.4636e-01,  1.2966e-01, -1.7152e-01,  3.1002e-02,\n",
       "           2.1310e-01,  2.2073e-01, -1.6647e-01, -1.0742e-02,  1.4345e-02,\n",
       "           1.6096e-01,  2.2832e-01, -1.4764e-01, -1.9274e-01, -6.8965e-03,\n",
       "          -8.5484e-02,  2.8300e-01, -5.6812e-02,  3.1991e-02, -3.6374e-02,\n",
       "           1.2094e-01, -4.4258e-03,  1.6134e-01,  2.3317e-01, -2.4694e-01,\n",
       "          -1.5172e-01,  1.3660e-01, -3.1591e-02, -1.5842e-01,  7.3159e-02,\n",
       "          -1.7609e-01, -2.3212e-01,  1.2307e-01, -7.0497e-03, -2.4196e-01,\n",
       "           9.0491e-03, -3.1774e-01, -1.1791e-01, -7.3285e-02,  5.6730e-02,\n",
       "          -2.3627e-01, -3.4953e-01,  8.9460e-02,  9.7281e-02, -2.8016e-01,\n",
       "          -1.1939e-01,  8.0084e-02, -1.0007e-02,  2.0137e-01,  7.7531e-02,\n",
       "           5.4589e-02, -1.4137e-01, -2.2748e-01,  1.9212e-01,  2.1033e-02,\n",
       "          -7.9633e-02,  1.1240e-01, -1.2824e-01,  3.9562e-01,  1.6551e-01,\n",
       "           2.5537e-01, -8.4647e-02, -1.6548e-01,  1.5045e-01,  1.5456e-03,\n",
       "          -6.3397e-02, -2.0671e-03, -8.6868e-02, -1.3686e-01,  2.9469e-03]],\n",
       "        grad_fn=<StackBackward>),\n",
       " tensor([[[[0.0956, 0.1311, 0.0708,  ..., 0.1004, 0.1130, 0.1004],\n",
       "           [0.0954, 0.1024, 0.0953,  ..., 0.1094, 0.1287, 0.0910],\n",
       "           [0.0674, 0.0666, 0.0994,  ..., 0.1608, 0.1417, 0.1187],\n",
       "           ...,\n",
       "           [0.0809, 0.0913, 0.1007,  ..., 0.1401, 0.1390, 0.0828],\n",
       "           [0.0948, 0.1500, 0.0581,  ..., 0.1145, 0.1172, 0.0913],\n",
       "           [0.0874, 0.1024, 0.1120,  ..., 0.1030, 0.1213, 0.0971]],\n",
       " \n",
       "          [[0.0801, 0.1099, 0.0995,  ..., 0.1055, 0.1181, 0.1252],\n",
       "           [0.0975, 0.1553, 0.0752,  ..., 0.1020, 0.1220, 0.0827],\n",
       "           [0.1073, 0.1474, 0.0573,  ..., 0.1016, 0.1159, 0.0818],\n",
       "           ...,\n",
       "           [0.0619, 0.0379, 0.1967,  ..., 0.1112, 0.0972, 0.1364],\n",
       "           [0.0803, 0.1131, 0.0863,  ..., 0.1197, 0.1308, 0.1056],\n",
       "           [0.1056, 0.1238, 0.0598,  ..., 0.1297, 0.1424, 0.0845]],\n",
       " \n",
       "          [[0.0783, 0.1552, 0.0563,  ..., 0.1334, 0.1513, 0.1127],\n",
       "           [0.0655, 0.0813, 0.1366,  ..., 0.1214, 0.1492, 0.1342],\n",
       "           [0.0818, 0.1288, 0.0716,  ..., 0.1250, 0.1392, 0.1041],\n",
       "           ...,\n",
       "           [0.1060, 0.1323, 0.0686,  ..., 0.1101, 0.1255, 0.0752],\n",
       "           [0.0912, 0.1032, 0.0736,  ..., 0.1198, 0.1158, 0.0841],\n",
       "           [0.0877, 0.0986, 0.0889,  ..., 0.1124, 0.1205, 0.0975]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.0751, 0.1168, 0.0853,  ..., 0.1417, 0.1406, 0.1038],\n",
       "           [0.0901, 0.0830, 0.0922,  ..., 0.1115, 0.1195, 0.1090],\n",
       "           [0.0882, 0.1060, 0.0876,  ..., 0.1360, 0.1547, 0.0955],\n",
       "           ...,\n",
       "           [0.0832, 0.0854, 0.1125,  ..., 0.1020, 0.1194, 0.1167],\n",
       "           [0.0823, 0.1413, 0.0707,  ..., 0.1019, 0.1118, 0.1131],\n",
       "           [0.0710, 0.0494, 0.1858,  ..., 0.1249, 0.1356, 0.1055]],\n",
       " \n",
       "          [[0.0728, 0.1466, 0.0738,  ..., 0.1196, 0.1339, 0.1280],\n",
       "           [0.0897, 0.1441, 0.0655,  ..., 0.0989, 0.0936, 0.1099],\n",
       "           [0.0658, 0.0697, 0.1145,  ..., 0.1397, 0.1541, 0.1383],\n",
       "           ...,\n",
       "           [0.0870, 0.1751, 0.0528,  ..., 0.1077, 0.1199, 0.0827],\n",
       "           [0.1207, 0.1234, 0.0660,  ..., 0.0883, 0.0830, 0.0668],\n",
       "           [0.0859, 0.1087, 0.0966,  ..., 0.1275, 0.1471, 0.0814]],\n",
       " \n",
       "          [[0.0803, 0.0774, 0.1336,  ..., 0.1110, 0.1161, 0.1187],\n",
       "           [0.0987, 0.0940, 0.0875,  ..., 0.1075, 0.1026, 0.0692],\n",
       "           [0.0842, 0.0726, 0.1265,  ..., 0.1041, 0.1073, 0.1152],\n",
       "           ...,\n",
       "           [0.0866, 0.1074, 0.1068,  ..., 0.1040, 0.1220, 0.1062],\n",
       "           [0.0813, 0.1361, 0.0598,  ..., 0.1380, 0.1343, 0.1000],\n",
       "           [0.0847, 0.1048, 0.0861,  ..., 0.1186, 0.1274, 0.0905]]],\n",
       " \n",
       " \n",
       "         [[[0.0960, 0.1595, 0.0534,  ..., 0.1067, 0.1130, 0.0855],\n",
       "           [0.0854, 0.1111, 0.0817,  ..., 0.1260, 0.1341, 0.1001],\n",
       "           [0.0765, 0.1053, 0.0975,  ..., 0.1203, 0.1356, 0.1107],\n",
       "           ...,\n",
       "           [0.0749, 0.0673, 0.1461,  ..., 0.1250, 0.1385, 0.1148],\n",
       "           [0.0827, 0.1191, 0.0844,  ..., 0.1156, 0.1310, 0.1100],\n",
       "           [0.0881, 0.1079, 0.0818,  ..., 0.1299, 0.1302, 0.0911]],\n",
       " \n",
       "          [[0.0764, 0.0842, 0.1115,  ..., 0.1357, 0.1529, 0.1116],\n",
       "           [0.0892, 0.1199, 0.0855,  ..., 0.1316, 0.1421, 0.0870],\n",
       "           [0.0888, 0.1296, 0.0793,  ..., 0.1074, 0.1151, 0.1014],\n",
       "           ...,\n",
       "           [0.0738, 0.1003, 0.0994,  ..., 0.1208, 0.1281, 0.1118],\n",
       "           [0.0758, 0.0931, 0.1209,  ..., 0.1201, 0.1351, 0.1132],\n",
       "           [0.0790, 0.0949, 0.1202,  ..., 0.0964, 0.1235, 0.1480]],\n",
       " \n",
       "          [[0.0842, 0.0803, 0.1121,  ..., 0.1203, 0.1179, 0.0942],\n",
       "           [0.0711, 0.1005, 0.0960,  ..., 0.1254, 0.1520, 0.1307],\n",
       "           [0.0855, 0.1152, 0.0897,  ..., 0.1066, 0.1259, 0.1125],\n",
       "           ...,\n",
       "           [0.0885, 0.1000, 0.0950,  ..., 0.1210, 0.1305, 0.1001],\n",
       "           [0.1000, 0.1078, 0.0808,  ..., 0.1151, 0.1164, 0.0764],\n",
       "           [0.1021, 0.2386, 0.0369,  ..., 0.0966, 0.1108, 0.0763]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.0924, 0.1240, 0.0694,  ..., 0.1148, 0.1188, 0.0884],\n",
       "           [0.0885, 0.1443, 0.0742,  ..., 0.1068, 0.1216, 0.1079],\n",
       "           [0.0707, 0.0798, 0.1278,  ..., 0.1189, 0.1348, 0.1301],\n",
       "           ...,\n",
       "           [0.0859, 0.0805, 0.1281,  ..., 0.1253, 0.1203, 0.0930],\n",
       "           [0.0900, 0.1257, 0.0781,  ..., 0.1176, 0.1473, 0.1079],\n",
       "           [0.0789, 0.0688, 0.1152,  ..., 0.1374, 0.1453, 0.1037]],\n",
       " \n",
       "          [[0.0871, 0.1294, 0.0788,  ..., 0.1148, 0.1302, 0.1097],\n",
       "           [0.0831, 0.1205, 0.0912,  ..., 0.1144, 0.1509, 0.1165],\n",
       "           [0.0869, 0.1200, 0.0812,  ..., 0.1088, 0.1249, 0.1208],\n",
       "           ...,\n",
       "           [0.0913, 0.1179, 0.0868,  ..., 0.1011, 0.1242, 0.1030],\n",
       "           [0.0787, 0.1252, 0.0828,  ..., 0.1108, 0.1208, 0.1022],\n",
       "           [0.0739, 0.1107, 0.0990,  ..., 0.1277, 0.1401, 0.1176]],\n",
       " \n",
       "          [[0.0802, 0.1020, 0.1153,  ..., 0.1034, 0.1301, 0.1342],\n",
       "           [0.0781, 0.0427, 0.1667,  ..., 0.1108, 0.1192, 0.1174],\n",
       "           [0.0888, 0.1408, 0.0638,  ..., 0.1243, 0.1492, 0.1085],\n",
       "           ...,\n",
       "           [0.0959, 0.1021, 0.0797,  ..., 0.1133, 0.1133, 0.0884],\n",
       "           [0.0921, 0.1485, 0.0698,  ..., 0.1037, 0.1273, 0.1103],\n",
       "           [0.0893, 0.1281, 0.0849,  ..., 0.1089, 0.1098, 0.0905]]],\n",
       " \n",
       " \n",
       "         [[[0.0962, 0.1229, 0.0769,  ..., 0.1051, 0.1240, 0.1034],\n",
       "           [0.0770, 0.1143, 0.1122,  ..., 0.1045, 0.1355, 0.1145],\n",
       "           [0.0803, 0.0817, 0.1036,  ..., 0.1078, 0.1442, 0.1566],\n",
       "           ...,\n",
       "           [0.0894, 0.1377, 0.0711,  ..., 0.1047, 0.1205, 0.1129],\n",
       "           [0.0828, 0.0779, 0.1227,  ..., 0.1136, 0.1403, 0.1295],\n",
       "           [0.0908, 0.1519, 0.0691,  ..., 0.1132, 0.1131, 0.0757]],\n",
       " \n",
       "          [[0.0826, 0.1116, 0.0763,  ..., 0.1187, 0.1308, 0.1209],\n",
       "           [0.0930, 0.1673, 0.0627,  ..., 0.1061, 0.1133, 0.0919],\n",
       "           [0.1044, 0.1215, 0.0599,  ..., 0.1254, 0.1419, 0.0883],\n",
       "           ...,\n",
       "           [0.0772, 0.0686, 0.1573,  ..., 0.1329, 0.1325, 0.0833],\n",
       "           [0.0778, 0.1387, 0.0797,  ..., 0.1038, 0.1156, 0.1187],\n",
       "           [0.1093, 0.1186, 0.0775,  ..., 0.1077, 0.1210, 0.0728]],\n",
       " \n",
       "          [[0.0636, 0.1062, 0.1056,  ..., 0.1359, 0.1648, 0.1292],\n",
       "           [0.0800, 0.0885, 0.1128,  ..., 0.1194, 0.1388, 0.1052],\n",
       "           [0.0835, 0.1449, 0.0601,  ..., 0.1259, 0.1675, 0.1112],\n",
       "           ...,\n",
       "           [0.0855, 0.1047, 0.0802,  ..., 0.1237, 0.1343, 0.1107],\n",
       "           [0.0761, 0.0655, 0.1412,  ..., 0.1303, 0.1308, 0.1054],\n",
       "           [0.1047, 0.1890, 0.0411,  ..., 0.0864, 0.0903, 0.0781]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.0773, 0.1079, 0.0960,  ..., 0.1182, 0.1281, 0.1085],\n",
       "           [0.1080, 0.1500, 0.0403,  ..., 0.1079, 0.1222, 0.0831],\n",
       "           [0.0730, 0.0981, 0.0991,  ..., 0.1193, 0.1487, 0.1471],\n",
       "           ...,\n",
       "           [0.0802, 0.1636, 0.0687,  ..., 0.1131, 0.0990, 0.0867],\n",
       "           [0.0864, 0.1219, 0.0958,  ..., 0.1017, 0.1071, 0.0905],\n",
       "           [0.0914, 0.0620, 0.1275,  ..., 0.1323, 0.1340, 0.0771]],\n",
       " \n",
       "          [[0.0930, 0.1675, 0.0636,  ..., 0.0988, 0.1238, 0.1084],\n",
       "           [0.0939, 0.2212, 0.0343,  ..., 0.1109, 0.1398, 0.0822],\n",
       "           [0.0859, 0.0963, 0.0873,  ..., 0.1297, 0.1352, 0.1002],\n",
       "           ...,\n",
       "           [0.0710, 0.1190, 0.0843,  ..., 0.1310, 0.1440, 0.1031],\n",
       "           [0.1134, 0.1184, 0.0622,  ..., 0.1043, 0.1047, 0.0666],\n",
       "           [0.0863, 0.1655, 0.0780,  ..., 0.0923, 0.1078, 0.1137]],\n",
       " \n",
       "          [[0.0873, 0.1094, 0.0880,  ..., 0.1141, 0.1200, 0.1149],\n",
       "           [0.0850, 0.0941, 0.0959,  ..., 0.1343, 0.1252, 0.0874],\n",
       "           [0.1054, 0.1497, 0.0459,  ..., 0.1007, 0.1096, 0.0731],\n",
       "           ...,\n",
       "           [0.0914, 0.1427, 0.0660,  ..., 0.1142, 0.1261, 0.0882],\n",
       "           [0.0852, 0.1059, 0.1106,  ..., 0.0971, 0.1267, 0.1230],\n",
       "           [0.0763, 0.0749, 0.1251,  ..., 0.1285, 0.1550, 0.1299]]],\n",
       " \n",
       " \n",
       "         [[[0.0888, 0.0727, 0.1098,  ..., 0.1228, 0.1227, 0.0856],\n",
       "           [0.0804, 0.0957, 0.1129,  ..., 0.1159, 0.1350, 0.1194],\n",
       "           [0.1000, 0.2273, 0.0347,  ..., 0.1008, 0.1207, 0.0769],\n",
       "           ...,\n",
       "           [0.0860, 0.1944, 0.0573,  ..., 0.0957, 0.1139, 0.0964],\n",
       "           [0.0973, 0.1491, 0.0622,  ..., 0.0935, 0.0932, 0.0750],\n",
       "           [0.0967, 0.1322, 0.0625,  ..., 0.0959, 0.1060, 0.1099]],\n",
       " \n",
       "          [[0.0890, 0.1258, 0.0874,  ..., 0.1009, 0.1242, 0.1172],\n",
       "           [0.0881, 0.1072, 0.0951,  ..., 0.0987, 0.1216, 0.1159],\n",
       "           [0.0736, 0.0947, 0.1114,  ..., 0.1133, 0.1334, 0.1393],\n",
       "           ...,\n",
       "           [0.0905, 0.1087, 0.0817,  ..., 0.1068, 0.1208, 0.1153],\n",
       "           [0.0882, 0.1072, 0.0869,  ..., 0.1180, 0.1361, 0.1096],\n",
       "           [0.0813, 0.0804, 0.1319,  ..., 0.1098, 0.1106, 0.0834]],\n",
       " \n",
       "          [[0.0837, 0.1777, 0.0637,  ..., 0.1080, 0.1247, 0.0977],\n",
       "           [0.1052, 0.1968, 0.0464,  ..., 0.0895, 0.1099, 0.0777],\n",
       "           [0.0879, 0.1216, 0.0730,  ..., 0.1190, 0.1266, 0.1014],\n",
       "           ...,\n",
       "           [0.0914, 0.2053, 0.0419,  ..., 0.0983, 0.1161, 0.1035],\n",
       "           [0.0625, 0.0649, 0.1477,  ..., 0.1217, 0.1563, 0.1548],\n",
       "           [0.0984, 0.0855, 0.0687,  ..., 0.1188, 0.1224, 0.0941]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.0825, 0.0724, 0.1282,  ..., 0.1176, 0.1305, 0.1071],\n",
       "           [0.0785, 0.0796, 0.1214,  ..., 0.1219, 0.1452, 0.1176],\n",
       "           [0.0854, 0.1273, 0.0671,  ..., 0.1158, 0.1386, 0.1184],\n",
       "           ...,\n",
       "           [0.0754, 0.1369, 0.0755,  ..., 0.1059, 0.1427, 0.1527],\n",
       "           [0.0822, 0.0602, 0.1400,  ..., 0.1269, 0.1231, 0.0901],\n",
       "           [0.0928, 0.2022, 0.0567,  ..., 0.0905, 0.1157, 0.0976]],\n",
       " \n",
       "          [[0.0986, 0.1280, 0.0812,  ..., 0.0848, 0.1048, 0.0873],\n",
       "           [0.0812, 0.0935, 0.1215,  ..., 0.0951, 0.1203, 0.1335],\n",
       "           [0.0892, 0.1502, 0.0576,  ..., 0.1094, 0.1245, 0.1041],\n",
       "           ...,\n",
       "           [0.0830, 0.0838, 0.1016,  ..., 0.1417, 0.1338, 0.1107],\n",
       "           [0.0856, 0.0871, 0.0896,  ..., 0.1217, 0.1146, 0.1061],\n",
       "           [0.1150, 0.1574, 0.0477,  ..., 0.0950, 0.1059, 0.0669]],\n",
       " \n",
       "          [[0.0975, 0.1741, 0.0492,  ..., 0.1008, 0.1026, 0.0716],\n",
       "           [0.0672, 0.1236, 0.0947,  ..., 0.1211, 0.1172, 0.1000],\n",
       "           [0.1053, 0.1520, 0.0629,  ..., 0.0982, 0.1119, 0.0832],\n",
       "           ...,\n",
       "           [0.0846, 0.0937, 0.1165,  ..., 0.1159, 0.1391, 0.1077],\n",
       "           [0.0918, 0.1580, 0.0608,  ..., 0.1199, 0.1450, 0.0909],\n",
       "           [0.0958, 0.1224, 0.0622,  ..., 0.1326, 0.1216, 0.0848]]]],\n",
       "        grad_fn=<CopySlices>),\n",
       " tensor([[[-0.0538, -0.1944,  0.0751,  ..., -0.2351, -0.8166,  1.8403],\n",
       "          [ 0.4064, -0.2699, -0.3666,  ..., -1.1525,  1.2840, -1.7983],\n",
       "          [-0.4949,  0.8738,  1.4963,  ..., -0.0641, -0.3366, -0.3797],\n",
       "          ...,\n",
       "          [ 0.1326, -0.0366, -0.8092,  ...,  0.3623,  0.7402, -1.1930],\n",
       "          [ 0.9467,  0.3926,  1.5898,  ..., -0.0168, -0.5009,  0.1295],\n",
       "          [-0.9088, -0.0478,  0.1987,  ..., -0.7414, -0.7635,  0.0039]],\n",
       " \n",
       "         [[-0.0702, -0.5028, -0.2276,  ...,  0.7746,  0.3777,  1.6753],\n",
       "          [ 0.5368,  0.7438,  0.5098,  ..., -2.0231,  0.4864, -0.7931],\n",
       "          [-0.0230,  0.8061,  1.2946,  ...,  0.3954,  0.2084, -1.4390],\n",
       "          ...,\n",
       "          [ 0.0677, -0.2142,  0.7555,  ..., -1.0251,  0.8996, -0.3806],\n",
       "          [ 0.9773,  0.7073,  1.8870,  ..., -0.5897,  0.0409, -0.4470],\n",
       "          [-0.1871,  0.6306,  0.5342,  ..., -0.2983, -1.1683, -0.0122]],\n",
       " \n",
       "         [[ 0.2035,  0.4032,  0.3374,  ..., -0.3963,  1.2126,  1.6733],\n",
       "          [ 0.5420,  0.6506,  0.3884,  ...,  0.3501,  1.3902,  1.1921],\n",
       "          [ 0.7483,  1.8405,  0.8223,  ...,  1.0786, -0.4770, -0.4826],\n",
       "          ...,\n",
       "          [ 0.0573,  0.1918,  1.6059,  ...,  1.1841,  1.0797,  0.3096],\n",
       "          [ 0.5890,  0.6434,  1.7761,  ...,  0.0154,  0.0200, -0.2820],\n",
       "          [ 0.4948,  0.9756,  0.1734,  ..., -0.7500, -0.4021,  0.0266]]],\n",
       "        grad_fn=<SqueezeBackward1>),\n",
       " Parameter containing:\n",
       " tensor([0.1145], requires_grad=True))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kwargs = {\"Nc\": 3, \"K1\": 4, \"K2\": 6, \"f1\": 3, \"f2\": 3, \"d2\": 3, \"d1\": 3, \"iW\": 32, \"iH\": 32}\n",
    "vae = VAE(**kwargs)\n",
    "vae(torch.randn(3, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caption Generator: RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created a simple figure to translate section 3.2 into a visual model architecture to help implement the model.\n",
    "\n",
    "<img src=\"./images/model_arch.jpg\" width=600>\n",
    "\n",
    "Therefore, we need 3 layers to perform caption generation:\n",
    "\n",
    "- 2 layered MLP with tanh and softmax activation\n",
    "    - Generates first word from $s^{(n)}$\n",
    "    - Last layer converts hidden state $h_t^{(n)}$ into one hot word vector $y_t^{(n)}$\n",
    "    \n",
    "- Embedding layer\n",
    "    - Converts one hot word vector $y_t^{(n)}$ into word representation $w_t^{(n)}$\n",
    "    \n",
    "- RNN (Can be LTSU or GRU)\n",
    "    - Recursively generates other words until the stop symbol is generated.\n",
    "    \n",
    "\n",
    "\n",
    "For the implementation below, I opted to use the indices instead of a one hot vector since the operations support indices better. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CaptionRNN(nn.Module):\n",
    "    \n",
    "    CAPTION_LIMIT = 30\n",
    "    \n",
    "    def __init__(self, V, M, H, C, stop_index):\n",
    "        \"\"\"\n",
    "        V: Size of the vocabulary\n",
    "        M: Size of embedded vector\n",
    "        H: Number of features for hidden state h\n",
    "        C: Flattened size of input code s\n",
    "        stop_index: The index that represents the end of a sentence.\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.mlp_l1 = nn.Linear(in_features=C, out_features=H)\n",
    "        self.mlp_l2 = nn.Linear(in_features=H, out_features=V)\n",
    "        \n",
    "        self.gru = nn.GRU(input_size=M, hidden_size=H, batch_first=True)\n",
    "        self.embedding = nn.Embedding(V, M)\n",
    "        self.stop_index = stop_index\n",
    "        \n",
    "        self.V = V\n",
    "    \n",
    "    def forward(self, x, limit=None):\n",
    "        \"\"\"\n",
    "        x: Unflattened code s.\n",
    "        Limit denotes the maximum number of words we should generate. \n",
    "            Default value can be set by changing CaptionRNN.CAPTION_LIMIT. \n",
    "        \"\"\"\n",
    "        \n",
    "        h1 = torch.tanh(self.mlp_l1(x.reshape(-1)))\n",
    "        prob_1 = F.softmax(self.mlp_l2(h1), dim=-1)\n",
    "        y1 = torch.multinomial(prob_1, 1)\n",
    "        \n",
    "        words = [y1]\n",
    "        probs = [prob_1]\n",
    "        ht = h1\n",
    "        wt = self.embedding(y1)\n",
    "        yt = -1\n",
    "        \n",
    "        # Prevents the RNN from possibly endlessly creating words\n",
    "        if not limit or limit < 0: \n",
    "            limit = CaptionRNN.CAPTION_LIMIT\n",
    "            \n",
    "        while len(words) < limit and not yt == self.stop_index:\n",
    "            # Output and hidden are the same in this case, so we just get the output. \n",
    "            \n",
    "            ht = self.gru(wt.unsqueeze(0), ht.unsqueeze(0).unsqueeze(0))[0]\n",
    "            ht = ht.squeeze(0).squeeze(0)\n",
    "            prob_t = F.softmax(self.mlp_l2(ht), dim=-1)\n",
    "            yt = torch.multinomial(prob_t, 1)\n",
    "            words.append(yt)\n",
    "            probs.append(prob_t)\n",
    "            wt = self.embedding(yt)\n",
    "    \n",
    "        return words\n",
    "    \n",
    "    \n",
    "    def caption_prob(self, x, y):\n",
    "        \"\"\"\n",
    "        Gets the probabilty of the caption being generated given the code x. \n",
    "        x: Unflattened code s.\n",
    "        y: Caption in the form [0, 1, 2, 3 ...], i.e shape (T, ) \n",
    "        \"\"\"\n",
    "        \n",
    "        h1 = torch.tanh(self.mlp_l1(x.reshape(-1)))\n",
    "        prob_1 = F.softmax(self.mlp_l2(h1), dim=-1)\n",
    "        \n",
    "        probs = [prob_1]\n",
    "        \n",
    "        ht = h1\n",
    "        wt = self.embedding(y[0])\n",
    "        \n",
    "        \n",
    "        for word in y[1:]:\n",
    "            ht = self.gru(wt.unsqueeze(0).unsqueeze(0), ht.unsqueeze(0).unsqueeze(0))[0]\n",
    "            ht = ht.squeeze(0).squeeze(0)\n",
    "            prob_t = F.softmax(self.mlp_l2(ht), dim=-1)\n",
    "            probs.append(prob_t)\n",
    "            wt = self.embedding(y[1])\n",
    "        \n",
    "        return torch.stack(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = CaptionRNN(V=10, M=20, H=20, C=600, stop_index=None)\n",
    "# test(torch.rand((6, 10, 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete model\n",
    "\n",
    "Finally, we put the VAE and CaptionRNN together to create the complete model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAECaption(nn.Module):\n",
    "    \n",
    "    def __init__(self, Nc, K1, K2, f1, f2, d2, d1, iW, iH, V, M, H, stop_index, pool_size=3):\n",
    "        \"\"\"\n",
    "        Nc: Number of channels of the image. \n",
    "        K1: Number of 2D \"slices\" in layer 1. This is shared for the encoder and decoder.\n",
    "        K2: Number of 2D \"slices\" in layer 2. This is shared for the encoder and decoder. \n",
    "        f1, f2: Kernel size for the first and second filter bank respectively\n",
    "        d2, d1: Kernel size for the second and first dictionary respectively. \n",
    "        iW, iH: width and height of the image. \n",
    "        V: Size of the vocabulary\n",
    "        M: Size of embedded vector\n",
    "        H: Number of features for hidden state h\n",
    "        stop_index: The index that indicates end of sentence.\n",
    "        \n",
    "        pool_size: The size of the pooling block. We are assuming that pooling blocks are square.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = CNNEncoder(Nc, K1, K2, f1, f2, iW, iH, pool_size)\n",
    "        cW, cH = iW // pool_size, iH // pool_size # code width, code height\n",
    "        self.decoder = DDGMDecoder(K2, K1, Nc, d2, d1, cW, cH, pool_size)\n",
    "        self.captioner = CaptionRNN(V, M, H, K2*cW*cH, stop_index)\n",
    "        \n",
    "    def forward(self, x, get_caption=True):\n",
    "        \"\"\"\n",
    "        x: Input image\n",
    "            Shape: (Nc, iW, iH)\n",
    "        Limit denotes the maximum number of words we should generate. \n",
    "            Default value can be set by changing CaptionRNN.CAPTION_LIMIT. \n",
    "        \"\"\"\n",
    "        \n",
    "        s, z, eta, mu, sigma = self.encoder(x)\n",
    "        z = z.type(torch.LongTensor)\n",
    "#         self.decoder.set_distribution(z)\n",
    "        x_reconstructed, mu_decoder = self.decoder(s, z)\n",
    "        if get_caption:\n",
    "            caption = self.captioner(s)\n",
    "        else:\n",
    "            caption = None\n",
    "        \n",
    "        # First four are the outputs. Next three are variables we got from the encoder.\n",
    "        # Next two are variables from the decoder.\n",
    "        \n",
    "        return x_reconstructed, caption, mu, sigma, eta, mu_decoder, self.decoder.get_precision()\n",
    "    \n",
    "    def caption_prob(self, x, y):\n",
    "        \"\"\"\n",
    "        Returns the probabilities of the caption y being generated given the input image x.\n",
    "        \"\"\"\n",
    "        s, z, eta, mu, sigma = self.encoder(x)\n",
    "        return self.captioner.caption_prob(s, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAECaption(Nc=3, K1 = 4, K2 = 6, f1=3, f2=3, d2=3, d1=3, iW=32, iH=32, V=20, M=30, H=40, stop_index=19)\n",
    "x_reconstructed, caption, mu, sigma, eta, mu_decoder, alpha = model(torch.rand((3, 32, 32)))\n",
    "# x_reconstructed, caption, mu, sigma, eta, mu_decoder, alpha = model(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss\n",
    "\n",
    "\n",
    "\n",
    "We use the equations provided in [the supplementary material](https://papers.nips.cc/paper/2016/file/eb86d510361fc23b59f18c1bc9802cc6-Supplemental.zip) to try and formulate the loss function.\n",
    "\n",
    "From equation (5) in the supplementary material, we have the following:\n",
    "\n",
    "$$ \\mathcal{L}(\\mathbf{X}, \\mathbf{Y}) = -D_{KL}[q_{\\phi}(\\mathbf{s} | \\mathbf{X})|| p_{\\alpha}(\\mathbf{s})] + \\mathbb{E}_{q_{\\phi}(\\mathbf{s} | \\mathbf{X})} \\Big\\{ \\xi log(p_{\\psi}(\\mathbf{Y} | \\mathbf{s})) + \\mathbb{E}_{q_{\\phi}(\\mathbf{z} | \\mathbf{X})} \\big[ log p_{\\alpha}(\\mathbf{X}, \\mathbf{z} | \\mathbf{s}) - log q_{\\phi}(\\mathbf{z} | \\mathbf{X}) \\big] \\Big\\}$$\n",
    "\n",
    "\n",
    "The paper gave us a closed form solution of the KL term (equation 6), which is: \n",
    "\n",
    "$$\\frac{1}{2} \\sum_{j=1}^{J}\\big[ 1 - \\mu_j^2 - \\sigma_j^2 + log (\\sigma_j^2) \\big]$$\n",
    "\n",
    "We have to modify the CNN encoder to return the mean and variance vectors as well.\n",
    "\n",
    "It also showed us a reparameterization trick to help get rid of the $q_{\\phi}(\\mathbf{s} | \\mathbf{X})$ in the expectation (equation 7). \n",
    "\n",
    "We denote $\\hat{\\mathbf{s}}$ and $\\hat{\\mathbf{z}}$ to be the code and pooling map returned by our encoder. We can now get an approximation of the expected value as: \n",
    "\n",
    "$$  \\xi log(p_{\\psi}(\\mathbf{Y} | \\hat{\\mathbf{s}}) + \\mathbb{E}_{q_{\\phi}(\\mathbf{z} | \\mathbf{X})} \\big[ log p_{\\alpha}(\\mathbf{X}, \\mathbf{z} | \\hat{\\mathbf{s}}) - log q_{\\phi}(\\mathbf{z} | \\mathbf{X}) \\big]  $$\n",
    "\n",
    "\n",
    "We focus on the second expectation first. We realize that we can rewrite the expectation as the following:\n",
    "\n",
    "$$-D_{KL}(q_{\\phi}(\\mathbf{z} | \\mathbf{X}) || p_{\\alpha}(\\mathbf{z} | \\hat{\\mathbf{s}})) + \\mathbb{E}_{q_{\\phi}(\\mathbf{z} | \\mathbf{X})} log p_{\\alpha}(\\mathbf{X}| \\mathbf{z} , \\hat{\\mathbf{s}})$$\n",
    "\n",
    "From [this math stackexchange post](https://math.stackexchange.com/questions/485810/kl-divergence-of-multinomial-distribution) we can get the following equation for the KL divergence between two multinomial distributions. We note that the prior is uniform. \n",
    "\n",
    "$$- (log(p) + \\frac{1}{p}\\sum_{m=1}^{p}log(\\eta_{i, j, k, m}))$$\n",
    "\n",
    "Where p is the size of the (square) pooling block, and $\\eta{i, j, k}$ represents the probability vector for pooling block i, j in layer k of the pooling map. To get the full KL divergence, we will simply sum across all pooling blocks in all layers.\n",
    "\n",
    "$$- \\sum_{i} \\sum_{j} \\sum_{k} (log(p) + \\frac{1}{p}\\sum_{m=1}^{p}log(\\eta_{i, j, k, m})) $$\n",
    "\n",
    "We can get an approximation of the expected value as: \n",
    "\n",
    "$$log p_{\\alpha}(\\mathbf{X}| \\hat{\\mathbf{z}}, \\hat{\\mathbf{s}})$$\n",
    "\n",
    "\n",
    "Let $d(\\mathbf{s}, \\mathbf{z})$ denote the operations we perform on the DDGM to get the mean of the data generation layer. Thus:\n",
    "\n",
    "$$p_{\\alpha}(\\mathbf{X}| \\hat{\\mathbf{z}}, \\hat{\\mathbf{s}}) = \\mathcal{N}(\\mathbf{X}; d(\\hat{\\mathbf{s}}, \\hat{\\mathbf{z}}), \\alpha_0^{-1}\\mathbf{I})$$. \n",
    "\n",
    "\n",
    "\n",
    "Therefore, we can get $log p_{\\alpha}(\\mathbf{X}| \\hat{\\mathbf{z}}, \\hat{\\mathbf{s}})$ as: \n",
    "\n",
    "$$\\frac{1}{2}\\bigg[\\sum_{k} log \\alpha_0 - \\big(\\alpha_0(\\mathbf{X} - d(\\hat{\\mathbf{s}}, \\hat{\\mathbf{z}}))^T (\\mathbf{X} - d(\\hat{\\mathbf{s}}, \\hat{\\mathbf{z}}) \\big)\\bigg]$$\n",
    "\n",
    "Where k is the dimension of X. (In this case, it's $N_x * N_y$)\n",
    "\n",
    "We need to modify the DDGM's forward method to return the mean. Note that we have to this for each layer in the image.\n",
    "\n",
    "\n",
    "Finally, for $\\xi log(p_{\\psi}(\\mathbf{Y} | \\mathbf{s}))$:\n",
    "\n",
    "$$p_{\\psi}(\\mathbf{Y} | \\mathbf{s}) = p(\\mathbf{y_1} | \\hat{\\mathbf{s}}) \\prod_{t=2}^{T} p(\\mathbf{y_t} | \\mathbf{y_{<t}}, \\hat{\\mathbf{s}})$$\n",
    "\n",
    "Where $p(\\mathbf{y_1} | \\hat{\\mathbf{s}})$ is $\\text{Softmax}(Vh_1)_{argmax(y_1)}$ and $p(\\mathbf{y_t} | \\mathbf{y_{<t}}, \\hat{\\mathbf{s}})$ is $\\text{Softmax}(Vh_t)_{argmax(y_t)}$, i.e the softmax value located at the index where $y_t = 1$.\n",
    "\n",
    "We can therefore get the equation: \n",
    "\n",
    "$$log (\\text{Softmax}(Vh_1)_{argmax(y_1)}) + \\sum_{t=2}^{T} log(\\text{Softmax}(Vh_t)_{argmax(y_t)}) $$\n",
    "\n",
    "\n",
    "Putting everything together, we have: \n",
    "\n",
    "\n",
    "$$\\frac{1}{2} \\sum_{j=1}^{J}\\big[ 1 - \\mu_j^2 - \\sigma_j^2 + log (\\sigma_j^2) \\big] - \\sum_{i} \\sum_{j} \\sum_{k} (log(p) + \\frac{1}{p}\\sum_{m=1}^{p}log(\\eta_{i, j, k, m}))  + \\frac{1}{2}\\bigg[\\sum log \\alpha_0 - \\big(\\alpha_0(\\mathbf{X} - d(\\hat{\\mathbf{s}}, \\hat{\\mathbf{z}}))^T (\\mathbf{X} - d(\\hat{\\mathbf{s}}, \\hat{\\mathbf{z}}) \\big)\\bigg] + \\xi \\big( log (\\text{Softmax}(Vh_1)_{argmax(y_1)}) + \\sum_{t=2}^{T} log(\\text{Softmax}(Vh_t)_{argmax(y_t)}) \\big)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL_gaussian(mu, sigma):\n",
    "    \"\"\"\n",
    "    Calculates the KL divergence term for the code.\n",
    "    \n",
    "    Note that the CNN calculates the log sigma, so we have to do appropiate transformations to get the correct\n",
    "    result. \n",
    "    \"\"\"\n",
    "    \n",
    "    vector = 1 - (mu ** 2) - torch.exp(2 * sigma) + (2 * sigma)\n",
    "    return 0.5 * vector.sum()\n",
    "\n",
    "def KL_multinomial(eta, pool_size):\n",
    "    \"\"\"\n",
    "    Calculate the KL divergence term for the pooling map.\n",
    "    Pool size should be the area, not the length of each square (VAE._pool_size ** 2)\n",
    "    \"\"\"\n",
    "    \n",
    "    return (torch.log(torch.Tensor([pool_size])) + (torch.log(eta).sum(axis=-1)/pool_size)).sum()\n",
    "\n",
    "def reconstruction_error(x, mu_decoder, alpha):\n",
    "    \"\"\"\n",
    "    Calculates the reconstruction error. \n",
    "    \n",
    "    Note that we store log(alpha) in the decoder, so we have to perform appropiate transformations to get the \n",
    "    correct result.\n",
    "    \n",
    "    When x and mu_decoder are of different shapes (due to the pooling layer), we will make x the same \n",
    "    shape as mu_decoder. \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    K, iW, iH = mu_decoder.shape\n",
    "    \n",
    "    x = x[:, :iW, :iH]\n",
    "    x_flat = x.reshape(-1)\n",
    "    mu_flat = mu_decoder.reshape(-1)\n",
    "    \n",
    "    p1 = alpha * (K*iW*iH)\n",
    "    p2 = torch.exp(alpha) * ((x_flat - mu_flat)**2).sum()\n",
    "    return 0.5 * (p1 - p2)\n",
    "    \n",
    "def caption_likelihood(y, probs):\n",
    "    \"\"\"\n",
    "    Calculates the caption likelihood.\n",
    "    \n",
    "    Since we the caption are represented as indexes, we do not have to do argmax anymore. \n",
    "    y has the shape (T, )\n",
    "        T: Number of words in this caption \n",
    "    \"\"\" \n",
    "    \n",
    "    prob_vectors = probs[np.arange(probs.shape[0]), y]\n",
    "    return torch.log(prob_vectors).sum()\n",
    "\n",
    "def calculate_loss(x, y, mu, sigma, eta, pool_size, mu_decoder, alpha, probs=None, xi=0, verbose=False):\n",
    "    \"\"\"\n",
    "    Calculates the loss of the VAE captioner. Default to unsupervised learning (uncaptioned image)\n",
    "    \"\"\"\n",
    "    \n",
    "    p1 = KL_gaussian(mu, sigma) \n",
    "    p2 = KL_multinomial(eta, pool_size)\n",
    "    p3 = reconstruction_error(x, mu_decoder, alpha)\n",
    "    p4 = (xi * caption_likelihood(y, probs) if xi else 0)\n",
    "    if verbose:\n",
    "        print(f\"Gaussian KL: {p1.item()}\")\n",
    "        print(f\"Multinomial KL: {-p2.item()}\")\n",
    "        print(f\"Reconstruction error: {p3.item()}\")\n",
    "    \n",
    "    \n",
    "    return p1 - p2 + p3 + p4\n",
    "#     return p1 + p3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torchvision.transforms import transforms\n",
    "import os\n",
    "import glob\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, transforms=None):\n",
    "        \n",
    "        self.images = glob.glob(\"./data/train/*.jpg\")\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        image = Image.open(self.images[0]).convert(\"RGB\")\n",
    "        \n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "        \n",
    "        return image\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((30, 30)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset = ImageDataset(transform)\n",
    "dataloader = DataLoader(dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\"Nc\": 3, \"K1\": 30, \"K2\": 40, \"f1\": 3, \"f2\": 3, \"d2\": 3, \"d1\": 3, \"iW\": 30, \"iH\": 30}\n",
    "model = VAE(**kwargs)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9297b8018a1b47e081fda77d7d73e5a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "losses = []\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    for image in dataloader: \n",
    "        image = image.squeeze(0)\n",
    "        x_reconstructed, mu, sigma, eta, mu_decoder, alpha = model(image)\n",
    "        loss = -calculate_loss(image, None, mu, sigma, eta, 9, mu_decoder, alpha)\n",
    "#         print(f\"Total Loss: {loss.item()}\")\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb897064250>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
